{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Session Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHEN Hang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: \n",
      "The predicted result: \n",
      "[1 2 1 0 0 0 2 1 2 0]\n",
      "The correct result: \n",
      "[1 1 1 0 0 0 2 1 2 0]\n",
      "The error is : 0.09999999999999998\n",
      "The optimal parameter k is : 8 and its accuracy is : 1.0\n",
      "\n",
      "Question2: \n",
      "The accuracy of svm : 0.9\n",
      "The accuracy of rf : 0.9\n",
      "The average accuracy of knn is : 0.9533333333333334\n",
      "The average accuracy of svm is : 0.9666666666666667\n",
      "The average accuracy of rf is : 0.9400000000000001\n",
      "The best is : svm\n",
      "\n",
      "Question3: \n",
      "The accuracy of newClf : 0.2\n",
      "The average accuracy of new clf is : 0.19285714285714278\n",
      "The accuracy of NewNewClf : 0.9\n",
      "The average accuracy of NewNewClf is : 0.85\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "# \n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_x = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Example in the pdf\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_x))\n",
    "iris_x_random = iris_x[indices]\n",
    "iris_y_random = iris_y[indices]\n",
    "iris_x_train = iris_x_random[:-10]\n",
    "iris_y_train = iris_y_random[:-10]\n",
    "iris_x_test = iris_x_random[-10:]\n",
    "iris_y_test = iris_y_random[-10:]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(iris_x_train,iris_y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris_y_result = knn.predict(iris_x_test)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Question1\n",
    "# error of the classifier\n",
    "print(\"Question1: \")\n",
    "print(\"The predicted result: \")\n",
    "print(iris_y_result)\n",
    "print(\"The correct result: \")\n",
    "print(iris_y_test)\n",
    "error = 1 - accuracy_score(iris_y_test,iris_y_result)\n",
    "print(\"The error is : {0}\".format(error))\n",
    "\n",
    "# the optional k of knn\n",
    "k_op = 0\n",
    "rate_max = 0\n",
    "for i in range(1,len(iris_x_train)+1):\n",
    "\tknn_op = KNeighborsClassifier(n_neighbors = i)\n",
    "\tknn_op.fit(iris_x_train,iris_y_train)\n",
    "\tknn_op_result = knn_op.predict(iris_x_test)\n",
    "\tif rate_max < accuracy_score(iris_y_test,knn_op_result):\n",
    "\t\trate_max = accuracy_score(iris_y_test,knn_op_result)\n",
    "\t\tk_op = i\n",
    "print(\"The optimal parameter k is : {0}\".format(k_op) + \" and its accuracy is : {0}\".format(rate_max))\n",
    "print()\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# Question2\n",
    "print(\"Question2: \")\n",
    "# use 2 other classifiers\n",
    "# First one: svm\n",
    "from sklearn import svm\n",
    "clf1 = svm.SVC(gamma=0.001, C=100.)\n",
    "clf1.fit(iris_x_train,iris_y_train)\n",
    "clf1.predict(iris_x_test)\n",
    "clf1_y_result = clf1.predict(iris_x_test)\n",
    "accuracy_clf1 = accuracy_score(iris_y_test,clf1_y_result)\n",
    "print(\"The accuracy of svm : {0}\".format(accuracy_clf1))\n",
    "\n",
    "# Second one: random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf2 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf2.fit(iris_x_train,iris_y_train)\n",
    "clf2.predict(iris_x_test)\n",
    "clf2_y_result = clf2.predict(iris_x_test)\n",
    "accuracy_clf2 = accuracy_score(iris_y_test,clf2_y_result)\n",
    "print(\"The accuracy of rf : {0}\".format(accuracy_clf2))\n",
    "\n",
    "# Use cross-validation to evaluate the classifiers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 15)\n",
    "kf.get_n_splits(iris_x)\n",
    "rate1 = []\n",
    "rate2 = []\n",
    "rate3 = []\n",
    "for train_index, test_index in kf.split(iris_x):\n",
    "\tx_train, x_test = iris_x_random[train_index], iris_x_random[test_index]\n",
    "\ty_train, y_test = iris_y_random[train_index], iris_y_random[test_index]\n",
    "\tclf1 = KNeighborsClassifier()\n",
    "\tclf2 = svm.SVC(gamma=0.001, C=100.)\n",
    "\tclf3 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\tclf1.fit(x_train,y_train)\n",
    "\tclf2.fit(x_train,y_train)\n",
    "\tclf3.fit(x_train,y_train)\n",
    "\ty_result1 = clf1.predict(x_test)\n",
    "\ty_result2 = clf2.predict(x_test)\n",
    "\ty_result3 = clf3.predict(x_test)\n",
    "\trate1.append(accuracy_score(y_test, y_result1))\n",
    "\trate2.append(accuracy_score(y_test, y_result2))\n",
    "\trate3.append(accuracy_score(y_test, y_result3))\n",
    "\n",
    "print(\"The average accuracy of knn is : {0}\".format(sum(rate1)/len(rate1)))\n",
    "print(\"The average accuracy of svm is : {0}\".format(sum(rate2)/len(rate2)))\n",
    "print(\"The average accuracy of rf is : {0}\".format(sum(rate3)/len(rate3)))\n",
    "\n",
    "# Compare evaluation results of the three classifiers\n",
    "\n",
    "list_rate = [sum(rate1)/len(rate1),sum(rate2)/len(rate2),sum(rate3)/len(rate3)]\n",
    "index_max = list_rate.index(max(list_rate))\n",
    "\n",
    "if index_max == 0:\n",
    "\tprint(\"The best is : knn\")\n",
    "elif index_max == 1:\n",
    "\tprint(\"The best is : svm\")\n",
    "else:\n",
    "\tprint(\"The best is : rf\")\n",
    "\n",
    "print()\n",
    "#----------------------------------------------------------\n",
    "print(\"Question3: \")\n",
    "\n",
    "\n",
    "# Write a majority class classifier: \n",
    "# a classifier that predicts the class label that is more frequent in the dataset\n",
    "class NewClassifier:\n",
    "\tdef __init__ (self): \n",
    "\t\tself.max_y = 0\n",
    "\n",
    "# The function fit will save the the most frequent value of Y \n",
    "\tdef fit(self, X, Y):\n",
    "\t\tfrom collections import Counter\n",
    "\t\tlist_y = np.unique(Y)\n",
    "\t\tnum_y = []\n",
    "\t\tfor i in range(0,len(list_y)):\n",
    "\t\t\tnum_y.append(Counter(Y)[list_y[i]])\n",
    "\t\tself.max_y = list_y[num_y.index(max(num_y))]\n",
    "\t\treturn self\n",
    "\n",
    "\tdef predict(self , X):\n",
    "\t\tlist_result = []\n",
    "\t\tfor i in range(0,len(X)):\n",
    "\t\t\tlist_result.append(self.max_y)\n",
    "\t\treturn list_result\n",
    "\n",
    "clff = NewClassifier()\n",
    "clff.fit(iris_x_train,iris_y_train)\n",
    "clff_y_result = clff.predict(iris_x_test)\n",
    "accuracy_clff = accuracy_score(iris_y_test,clff_y_result)\n",
    "print(\"The accuracy of newClf : {0}\".format(accuracy_clff))\n",
    "\n",
    "\n",
    "# Use the majority class classifier to evaluate one dataset\n",
    "# and justify why the evaluation results using the new classifier are correct\n",
    "rate4 = []\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(iris_x_train):\n",
    "\tx_train, x_test = iris_x_train[train_index], iris_x_train[test_index]\n",
    "\ty_train, y_test = iris_y_train[train_index], iris_y_train[test_index]\n",
    "\tclf4 = NewClassifier()\n",
    "\tclf4.fit(x_train,y_train)\n",
    "\ty_result4 = clf4.predict(x_test)\n",
    "\trate4.append(accuracy_score(y_test, y_result4))\n",
    "print(\"The average accuracy of new clf is : {0}\".format(sum(rate4)/len(rate4)))\n",
    "\n",
    "\n",
    "# Create another classifier with higher performance than the majority class classifier\n",
    "class NewNewClassifier:\n",
    "\tdef __init__ (self): \n",
    "\t\tself.train_x = []\n",
    "\t\tself.train_y = []\n",
    "\n",
    "# This method will classify by the sum of the data, the keep their average of sum\n",
    "# The classifier will return the result whose average of sum is most closed to that of test data\n",
    "\tdef fit(self, X, Y):\n",
    "\t\tlist_y = np.unique(Y)\n",
    "\t\tsort_x = [[] for i in range(len(list_y))]\n",
    "\t\tfor i in range(0,len(X)):\n",
    "\t\t\tsort_x[list_y.tolist().index(Y[i])].append(sum(X[i]))\n",
    "\t\tfor j in range(0,len(sort_x)):\n",
    "\t\t\tself.train_x.append(sum(sort_x[j])/len(sort_x[j]))\n",
    "\t\tself.train_y = list_y\n",
    "\t\treturn self\n",
    "\n",
    "\tdef predict(self , X):\n",
    "\t\tlist_result = []\n",
    "\t\tfor i in range(len(X)):\n",
    "\t\t\tlist_compare = []\n",
    "\t\t\tfor j in range(len(self.train_x)):\n",
    "\t\t\t\tlist_compare.append(abs(self.train_x[j] - sum(X[i])))\n",
    "\t\t\tlist_result.append(self.train_y[list_compare.index(min(list_compare))])\n",
    "\t\treturn list_result\n",
    "clfff = NewNewClassifier()\n",
    "clfff.fit(iris_x_train,iris_y_train)\n",
    "clfff_y_result = clfff.predict(iris_x_test)\n",
    "accuracy_clfff = accuracy_score(iris_y_test,clfff_y_result)\n",
    "print(\"The accuracy of NewNewClf : {0}\".format(accuracy_clfff))\n",
    "\n",
    "rate5 = []\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, test_index in kf.split(iris_x_train):\n",
    "\tx_train, x_test = iris_x_train[train_index], iris_x_train[test_index]\n",
    "\ty_train, y_test = iris_y_train[train_index], iris_y_train[test_index]\n",
    "\tclf5 = NewNewClassifier()\n",
    "\tclf5.fit(x_train,y_train)\n",
    "\ty_result5 = clf5.predict(x_test)\n",
    "\trate5.append(accuracy_score(y_test, y_result5))\n",
    "print(\"The average accuracy of NewNewClf is : {0}\".format(sum(rate5)/len(rate5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
