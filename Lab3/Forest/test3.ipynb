{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "Start\n",
      "train over\n",
      "Compelte\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# path1 = '/home/jian/DATA_SETS/kaggle/forests/train.csv'\n",
    "# path2 = '/home/jian/DATA_SETS/kaggle/forests/test.csv'\n",
    "\n",
    "path1 = 'all/train-set.csv'\n",
    "path2 = 'all/test-set.csv'\n",
    "\n",
    "submission = 'submission.csv'\n",
    "\n",
    "\n",
    "def preprocess(data2):\n",
    "    data = data2\n",
    "    feature_cols_for_filling_missing = [col for col in data.columns if col not in ['Hillshade_3pm', 'Id']]\n",
    "    X_train = data[feature_cols_for_filling_missing][data.Hillshade_3pm != 0]\n",
    "    y_train = data['Hillshade_3pm'][data.Hillshade_3pm != 0]\n",
    "    X_test = data[feature_cols_for_filling_missing][data.Hillshade_3pm == 0]\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    rfg = RandomForestRegressor()\n",
    "    rfg.fit(X_train, y_train)\n",
    "    data.Hillshade_3pm.loc[data.Hillshade_3pm == 0] = np.around(rfg.predict(X_test))\n",
    "    return data\n",
    "\n",
    "\n",
    "def feature_engineering(data2):\n",
    "    data = data2\n",
    "\n",
    "    data['Ele_minus_VDtHyd'] = data.Elevation - data.Vertical_Distance_To_Hydrology\n",
    "\n",
    "    data['Ele_plus_VDtHyd'] = data.Elevation + data.Vertical_Distance_To_Hydrology\n",
    "\n",
    "    data['Distanse_to_Hydrolody'] = (data['Horizontal_Distance_To_Hydrology'] ** 2 + data[\n",
    "        'Vertical_Distance_To_Hydrology'] ** 2) ** 0.5\n",
    "\n",
    "    data['Hydro_plus_Fire'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "    data['Hydro_minus_Fire'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "    data['Hydro_plus_Road'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Roadways']\n",
    "\n",
    "    data['Hydro_minus_Road'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Roadways']\n",
    "\n",
    "    data['Fire_plus_Road'] = data['Horizontal_Distance_To_Fire_Points'] + data['Horizontal_Distance_To_Roadways']\n",
    "\n",
    "    data['Fire_minus_Road'] = data['Horizontal_Distance_To_Fire_Points'] - data['Horizontal_Distance_To_Roadways']\n",
    "\n",
    "    data['Soil'] = 0\n",
    "    for i in range(1, 41):\n",
    "        data['Soil'] = data['Soil'] + i * data['Soil_Type' + str(i)]\n",
    "\n",
    "    data['Wilderness_Area'] = 0\n",
    "    for i in range(1, 5):\n",
    "        data['Wilderness_Area'] = data['Wilderness_Area'] + i * data['Wilderness_Area' + str(i)]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_features():\n",
    "    return ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points',\n",
    "            'Ele_minus_VDtHyd', 'Ele_plus_VDtHyd', 'Distanse_to_Hydrolody', 'Hydro_plus_Fire', 'Hydro_minus_Fire',\n",
    "            'Hydro_plus_Road',\n",
    "            'Hydro_minus_Road', 'Fire_plus_Road', 'Fire_minus_Road', 'Soil', 'Wilderness_Area']\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_df = pd.read_csv(path1)\n",
    "    test_df = pd.read_csv(path2)\n",
    "\n",
    "#     train_df = preprocess(train_df)\n",
    "#     test_df = preprocess(test_df)\n",
    "\n",
    "    train_df = feature_engineering(train_df)\n",
    "    test_df = feature_engineering(test_df)\n",
    "\n",
    "    features = get_features()\n",
    "\n",
    "    y_train = train_df['Cover_Type'].values\n",
    "    test_id = test_df['Id']\n",
    "    X_train = train_df[:][features].values\n",
    "\n",
    "    # X_test = test_df[:][features]\n",
    "\n",
    "    def split_X_test():\n",
    "\n",
    "        length = len(test_df)\n",
    "        n = length // 10000\n",
    "        print(n)\n",
    "        split_test_data = []\n",
    "\n",
    "        for i in range(n):\n",
    "            split_test_data.append(test_df[i * 10000:(i + 1) * 10000][features].values)\n",
    "\n",
    "        split_test_data.append(test_df[n * 10000:length][features].values)\n",
    "\n",
    "        return split_test_data\n",
    "\n",
    "    X_test = split_X_test()\n",
    "\n",
    "    print('Start')\n",
    "\n",
    "    clf = ExtraTreesClassifier(max_features=0.3, n_estimators=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print('train over')\n",
    "\n",
    "    y_predict = []\n",
    "\n",
    "    for var in X_test:\n",
    "        y_predict.extend(clf.predict(var))\n",
    "\n",
    "    submission = pd.DataFrame(data={'Id': test_id, 'Cover_Type': y_predict})\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "    print('Compelte')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# path1 = '/home/jian/DATA_SETS/kaggle/forests/train.csv'\n",
    "# path2 = '/home/jian/DATA_SETS/kaggle/forests/test.csv'\n",
    "\n",
    "path1 = 'all/train-set.csv'\n",
    "path2 = 'all/test-set.csv'\n",
    "\n",
    "submission = 'submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 528720 entries, 0 to 528719\n",
      "Data columns (total 56 columns):\n",
      "Id                                    528720 non-null int64\n",
      "Elevation                             528720 non-null int64\n",
      "Aspect                                528720 non-null int64\n",
      "Slope                                 528720 non-null int64\n",
      "Horizontal_Distance_To_Hydrology      528720 non-null int64\n",
      "Vertical_Distance_To_Hydrology        528720 non-null int64\n",
      "Horizontal_Distance_To_Roadways       528720 non-null int64\n",
      "Hillshade_9am                         528720 non-null int64\n",
      "Hillshade_Noon                        528720 non-null int64\n",
      "Hillshade_3pm                         528720 non-null float64\n",
      "Horizontal_Distance_To_Fire_Points    528720 non-null int64\n",
      "Wilderness_Area1                      528720 non-null int64\n",
      "Wilderness_Area2                      528720 non-null int64\n",
      "Wilderness_Area3                      528720 non-null int64\n",
      "Wilderness_Area4                      528720 non-null int64\n",
      "Soil_Type1                            528720 non-null int64\n",
      "Soil_Type2                            528720 non-null int64\n",
      "Soil_Type3                            528720 non-null int64\n",
      "Soil_Type4                            528720 non-null int64\n",
      "Soil_Type5                            528720 non-null int64\n",
      "Soil_Type6                            528720 non-null int64\n",
      "Soil_Type7                            528720 non-null int64\n",
      "Soil_Type8                            528720 non-null int64\n",
      "Soil_Type9                            528720 non-null int64\n",
      "Soil_Type10                           528720 non-null int64\n",
      "Soil_Type11                           528720 non-null int64\n",
      "Soil_Type12                           528720 non-null int64\n",
      "Soil_Type13                           528720 non-null int64\n",
      "Soil_Type14                           528720 non-null int64\n",
      "Soil_Type15                           528720 non-null int64\n",
      "Soil_Type16                           528720 non-null int64\n",
      "Soil_Type17                           528720 non-null int64\n",
      "Soil_Type18                           528720 non-null int64\n",
      "Soil_Type19                           528720 non-null int64\n",
      "Soil_Type20                           528720 non-null int64\n",
      "Soil_Type21                           528720 non-null int64\n",
      "Soil_Type22                           528720 non-null int64\n",
      "Soil_Type23                           528720 non-null int64\n",
      "Soil_Type24                           528720 non-null int64\n",
      "Soil_Type25                           528720 non-null int64\n",
      "Soil_Type26                           528720 non-null int64\n",
      "Soil_Type27                           528720 non-null int64\n",
      "Soil_Type28                           528720 non-null int64\n",
      "Soil_Type29                           528720 non-null int64\n",
      "Soil_Type30                           528720 non-null int64\n",
      "Soil_Type31                           528720 non-null int64\n",
      "Soil_Type32                           528720 non-null int64\n",
      "Soil_Type33                           528720 non-null int64\n",
      "Soil_Type34                           528720 non-null int64\n",
      "Soil_Type35                           528720 non-null int64\n",
      "Soil_Type36                           528720 non-null int64\n",
      "Soil_Type37                           528720 non-null int64\n",
      "Soil_Type38                           528720 non-null int64\n",
      "Soil_Type39                           528720 non-null int64\n",
      "Soil_Type40                           528720 non-null int64\n",
      "Cover_Type                            528720 non-null int64\n",
      "dtypes: float64(1), int64(55)\n",
      "memory usage: 225.9 MB\n"
     ]
    }
   ],
   "source": [
    "def preprocess(data2):\n",
    "    data = data2\n",
    "    feature_cols_for_filling_missing = [col for col in data.columns if col not in ['Hillshade_3pm', 'Id']]\n",
    "    X_train = data[feature_cols_for_filling_missing][data.Hillshade_3pm != 0]\n",
    "    y_train = data['Hillshade_3pm'][data.Hillshade_3pm != 0]\n",
    "    X_test = data[feature_cols_for_filling_missing][data.Hillshade_3pm == 0]\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    rfg = RandomForestRegressor()\n",
    "    rfg.fit(X_train, y_train)\n",
    "    data.Hillshade_3pm.loc[data.Hillshade_3pm == 0] = np.around(rfg.predict(X_test))\n",
    "    return data\n",
    "train_df = pd.read_csv(path1)\n",
    "test_df = pd.read_csv(path2)\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 528720 entries, 0 to 528719\n",
      "Data columns (total 56 columns):\n",
      "Id                                    528720 non-null int64\n",
      "Elevation                             528720 non-null int64\n",
      "Aspect                                528720 non-null int64\n",
      "Slope                                 528720 non-null int64\n",
      "Horizontal_Distance_To_Hydrology      528720 non-null int64\n",
      "Vertical_Distance_To_Hydrology        528720 non-null int64\n",
      "Horizontal_Distance_To_Roadways       528720 non-null int64\n",
      "Hillshade_9am                         528720 non-null int64\n",
      "Hillshade_Noon                        528720 non-null int64\n",
      "Hillshade_3pm                         528720 non-null int64\n",
      "Horizontal_Distance_To_Fire_Points    528720 non-null int64\n",
      "Wilderness_Area1                      528720 non-null int64\n",
      "Wilderness_Area2                      528720 non-null int64\n",
      "Wilderness_Area3                      528720 non-null int64\n",
      "Wilderness_Area4                      528720 non-null int64\n",
      "Soil_Type1                            528720 non-null int64\n",
      "Soil_Type2                            528720 non-null int64\n",
      "Soil_Type3                            528720 non-null int64\n",
      "Soil_Type4                            528720 non-null int64\n",
      "Soil_Type5                            528720 non-null int64\n",
      "Soil_Type6                            528720 non-null int64\n",
      "Soil_Type7                            528720 non-null int64\n",
      "Soil_Type8                            528720 non-null int64\n",
      "Soil_Type9                            528720 non-null int64\n",
      "Soil_Type10                           528720 non-null int64\n",
      "Soil_Type11                           528720 non-null int64\n",
      "Soil_Type12                           528720 non-null int64\n",
      "Soil_Type13                           528720 non-null int64\n",
      "Soil_Type14                           528720 non-null int64\n",
      "Soil_Type15                           528720 non-null int64\n",
      "Soil_Type16                           528720 non-null int64\n",
      "Soil_Type17                           528720 non-null int64\n",
      "Soil_Type18                           528720 non-null int64\n",
      "Soil_Type19                           528720 non-null int64\n",
      "Soil_Type20                           528720 non-null int64\n",
      "Soil_Type21                           528720 non-null int64\n",
      "Soil_Type22                           528720 non-null int64\n",
      "Soil_Type23                           528720 non-null int64\n",
      "Soil_Type24                           528720 non-null int64\n",
      "Soil_Type25                           528720 non-null int64\n",
      "Soil_Type26                           528720 non-null int64\n",
      "Soil_Type27                           528720 non-null int64\n",
      "Soil_Type28                           528720 non-null int64\n",
      "Soil_Type29                           528720 non-null int64\n",
      "Soil_Type30                           528720 non-null int64\n",
      "Soil_Type31                           528720 non-null int64\n",
      "Soil_Type32                           528720 non-null int64\n",
      "Soil_Type33                           528720 non-null int64\n",
      "Soil_Type34                           528720 non-null int64\n",
      "Soil_Type35                           528720 non-null int64\n",
      "Soil_Type36                           528720 non-null int64\n",
      "Soil_Type37                           528720 non-null int64\n",
      "Soil_Type38                           528720 non-null int64\n",
      "Soil_Type39                           528720 non-null int64\n",
      "Soil_Type40                           528720 non-null int64\n",
      "Cover_Type                            528720 non-null int64\n",
      "dtypes: int64(56)\n",
      "memory usage: 225.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(path1)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train_df = pd.read_csv(path1)\n",
    "test_df = pd.read_csv(path2)\n",
    "\n",
    "# train_df = preprocess(train_df)\n",
    "# test_df = preprocess(test_df)\n",
    "\n",
    "def feature_change(data_input):\n",
    "    data = data_input\n",
    "    data['Ele_minus_VDtHyd'] = data.Elevation - data.Vertical_Distance_To_Hydrology\n",
    "    data['Ele_plus_VDtHyd'] = data.Elevation + data.Vertical_Distance_To_Hydrology\n",
    "    data['Distanse_to_Hydrolody'] = (data['Horizontal_Distance_To_Hydrology'] ** 2 + data['Vertical_Distance_To_Hydrology'] ** 2) ** 0.5\n",
    "    data['Hydro_plus_Fire'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Fire_Points']\n",
    "    data['Hydro_minus_Fire'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Fire_Points']\n",
    "    data['Hydro_plus_Road'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Roadways']\n",
    "    data['Hydro_minus_Road'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Roadways']\n",
    "    data['Fire_plus_Road'] = data['Horizontal_Distance_To_Fire_Points'] + data['Horizontal_Distance_To_Roadways']\n",
    "    data['Fire_minus_Road'] = data['Horizontal_Distance_To_Fire_Points'] - data['Horizontal_Distance_To_Roadways']\n",
    "    data['Soil'] = 0\n",
    "    for i in range(1, 41):\n",
    "        data['Soil'] = data['Soil'] + i * data['Soil_Type' + str(i)]\n",
    "    data['Wilderness_Area'] = 0\n",
    "    for i in range(1, 5):\n",
    "        data['Wilderness_Area'] = data['Wilderness_Area'] + i * data['Wilderness_Area' + str(i)]\n",
    "    for i in range(1, 41):\n",
    "        data = data.drop(['Soil_Type' + str(i)], axis=1)\n",
    "    for i in range(1, 5):\n",
    "        data = data.drop(['Wilderness_Area' + str(i)], axis=1)\n",
    "    return data\n",
    "\n",
    "def get_features():\n",
    "    return ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points',\n",
    "            'Ele_minus_VDtHyd', 'Ele_plus_VDtHyd', 'Distanse_to_Hydrolody', 'Hydro_plus_Fire', 'Hydro_minus_Fire',\n",
    "            'Hydro_plus_Road',\n",
    "            'Hydro_minus_Road', 'Fire_plus_Road', 'Fire_minus_Road', 'Soil', 'Wilderness_Area']\n",
    "\n",
    "train_df = feature_change(train_df)\n",
    "test_df = feature_change(test_df)\n",
    "\n",
    "features = get_features()\n",
    "\n",
    "y_train = train_df['Cover_Type'].values\n",
    "test_id = test_df['Id']\n",
    "X_train = train_df[:][features].values\n",
    "\n",
    "def split_X_test():\n",
    "\n",
    "    length = len(test_df)\n",
    "    n = length // 10000\n",
    "    print(n)\n",
    "    split_test_data = []\n",
    "\n",
    "    for i in range(n):\n",
    "        split_test_data.append(test_df[i * 10000:(i + 1) * 10000][features].values)\n",
    "\n",
    "    split_test_data.append(test_df[n * 10000:length][features].values)\n",
    "\n",
    "    return split_test_data\n",
    "\n",
    "X_test = split_X_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df[:][features].values\n",
    "print(len(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "train over\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 2.9530000e+03  2.2400000e+02  9.0000000e+00  5.5000000e+01\n  1.1000000e+01  1.6000000e+03  2.0600000e+02  2.5100000e+02\n  1.7600000e+02  1.6690000e+03  2.9420000e+03  2.9640000e+03\n  5.6089214e+01  1.7240000e+03 -1.6140000e+03  1.6550000e+03\n -1.5450000e+03  3.2690000e+03  6.9000000e+01  3.2000000e+01\n  3.0000000e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8a6f4a0130a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cover_Type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    375\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 2.9530000e+03  2.2400000e+02  9.0000000e+00  5.5000000e+01\n  1.1000000e+01  1.6000000e+03  2.0600000e+02  2.5100000e+02\n  1.7600000e+02  1.6690000e+03  2.9420000e+03  2.9640000e+03\n  5.6089214e+01  1.7240000e+03 -1.6140000e+03  1.6550000e+03\n -1.5450000e+03  3.2690000e+03  6.9000000e+01  3.2000000e+01\n  3.0000000e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train_df = pd.read_csv(path1)\n",
    "test_df = pd.read_csv(path2)\n",
    "\n",
    "# train_df = preprocess(train_df)\n",
    "# test_df = preprocess(test_df)\n",
    "\n",
    "def feature_change(data_input):\n",
    "    data = data_input\n",
    "    data['Ele_minus_VDtHyd'] = data.Elevation - data.Vertical_Distance_To_Hydrology\n",
    "    data['Ele_plus_VDtHyd'] = data.Elevation + data.Vertical_Distance_To_Hydrology\n",
    "    data['Distanse_to_Hydrolody'] = (data['Horizontal_Distance_To_Hydrology'] ** 2 + data['Vertical_Distance_To_Hydrology'] ** 2) ** 0.5\n",
    "    data['Hydro_plus_Fire'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Fire_Points']\n",
    "    data['Hydro_minus_Fire'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Fire_Points']\n",
    "    data['Hydro_plus_Road'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Roadways']\n",
    "    data['Hydro_minus_Road'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Roadways']\n",
    "    data['Fire_plus_Road'] = data['Horizontal_Distance_To_Fire_Points'] + data['Horizontal_Distance_To_Roadways']\n",
    "    data['Fire_minus_Road'] = data['Horizontal_Distance_To_Fire_Points'] - data['Horizontal_Distance_To_Roadways']\n",
    "    data['Soil'] = 0\n",
    "    for i in range(1, 41):\n",
    "        data['Soil'] = data['Soil'] + i * data['Soil_Type' + str(i)]\n",
    "    data['Wilderness_Area'] = 0\n",
    "    for i in range(1, 5):\n",
    "        data['Wilderness_Area'] = data['Wilderness_Area'] + i * data['Wilderness_Area' + str(i)]\n",
    "    for i in range(1, 41):\n",
    "        data = data.drop(['Soil_Type' + str(i)], axis=1)\n",
    "    for i in range(1, 5):\n",
    "        data = data.drop(['Wilderness_Area' + str(i)], axis=1)\n",
    "    return data\n",
    "\n",
    "def get_features():\n",
    "    return ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points',\n",
    "            'Ele_minus_VDtHyd', 'Ele_plus_VDtHyd', 'Distanse_to_Hydrolody', 'Hydro_plus_Fire', 'Hydro_minus_Fire',\n",
    "            'Hydro_plus_Road',\n",
    "            'Hydro_minus_Road', 'Fire_plus_Road', 'Fire_minus_Road', 'Soil', 'Wilderness_Area']\n",
    "\n",
    "train_df = feature_change(train_df)\n",
    "test_df = feature_change(test_df)\n",
    "\n",
    "features = get_features()\n",
    "\n",
    "y_train = train_df['Cover_Type'].values\n",
    "test_id = test_df['Id']\n",
    "X_train = train_df[:][features].values\n",
    "X_test = test_df[:][features].values\n",
    "\n",
    "# def split_X_test():\n",
    "\n",
    "#     length = len(test_df)\n",
    "#     n = length // 10000\n",
    "#     print(n)\n",
    "#     split_test_data = []\n",
    "\n",
    "#     for i in range(n):\n",
    "#         split_test_data.append(test_df[i * 10000:(i + 1) * 10000][features].values)\n",
    "\n",
    "#     split_test_data.append(test_df[n * 10000:length][features].values)\n",
    "\n",
    "#     return split_test_data\n",
    "\n",
    "# X_test = split_X_test()\n",
    "\n",
    "print('Start')\n",
    "\n",
    "clf = ExtraTreesClassifier(max_features=0.3, n_estimators=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('train over')\n",
    "\n",
    "y_predict = []\n",
    "\n",
    "for var in X_test:\n",
    "    y_predict.extend(clf.predict(var))\n",
    "\n",
    "submission = pd.DataFrame(data={'Id': test_id, 'Cover_Type': y_predict})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print('Compelte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compelte\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(data={'Id': test_id, 'Cover_Type': y_predict})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print('Compelte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "train over\n",
      "Compelte\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train_df = pd.read_csv('all/train-set.csv')\n",
    "test_df = pd.read_csv('all/test-set.csv')\n",
    "\n",
    "def change_feature(data_input):\n",
    "    data = data_input\n",
    "    data['Ele_minus_VDtHyd'] = data.Elevation - data.Vertical_Distance_To_Hydrology\n",
    "    data['Ele_plus_VDtHyd'] = data.Elevation + data.Vertical_Distance_To_Hydrology\n",
    "    data['Distanse_to_Hydrolody'] = (data['Horizontal_Distance_To_Hydrology'] ** 2 + data['Vertical_Distance_To_Hydrology'] ** 2) ** 0.5\n",
    "    data['Hydro_plus_Fire'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Fire_Points']\n",
    "    data['Hydro_minus_Fire'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Fire_Points']\n",
    "    data['Hydro_plus_Road'] = data['Horizontal_Distance_To_Hydrology'] + data['Horizontal_Distance_To_Roadways']\n",
    "    data['Hydro_minus_Road'] = data['Horizontal_Distance_To_Hydrology'] - data['Horizontal_Distance_To_Roadways']\n",
    "    data['Fire_plus_Road'] = data['Horizontal_Distance_To_Fire_Points'] + data['Horizontal_Distance_To_Roadways']\n",
    "    data['Fire_minus_Road'] = data['Horizontal_Distance_To_Fire_Points'] - data['Horizontal_Distance_To_Roadways']\n",
    "    data['Soil'] = 0\n",
    "    for i in range(1, 41):\n",
    "        data['Soil'] = data['Soil'] + i * data['Soil_Type' + str(i)]\n",
    "    data['Wilderness_Area'] = 0\n",
    "    for i in range(1, 5):\n",
    "        data['Wilderness_Area'] = data['Wilderness_Area'] + i * data['Wilderness_Area' + str(i)]\n",
    "    for i in range(1, 41):\n",
    "        data = data.drop(['Soil_Type' + str(i)], axis=1)\n",
    "    for i in range(1, 5):\n",
    "        data = data.drop(['Wilderness_Area' + str(i)], axis=1)\n",
    "    return data\n",
    "\n",
    "def get_features():\n",
    "    return ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "            'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "            'Horizontal_Distance_To_Fire_Points',\n",
    "            'Ele_minus_VDtHyd', 'Ele_plus_VDtHyd', 'Distanse_to_Hydrolody', 'Hydro_plus_Fire', 'Hydro_minus_Fire',\n",
    "            'Hydro_plus_Road',\n",
    "            'Hydro_minus_Road', 'Fire_plus_Road', 'Fire_minus_Road', 'Soil', 'Wilderness_Area']\n",
    "\n",
    "train_df = change_feature(train_df)\n",
    "test_df = change_feature(test_df)\n",
    "\n",
    "features = get_features()\n",
    "\n",
    "y_train = train_df['Cover_Type'].values\n",
    "test_id = test_df['Id']\n",
    "X_train = train_df[:][features].values\n",
    "X_test = test_df[:][features].values\n",
    "\n",
    "\n",
    "print('Start')\n",
    "\n",
    "clf = ExtraTreesClassifier(max_features=0.3, n_estimators=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('train over')\n",
    "\n",
    "output = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# submission = pd.DataFrame(data={'Id': test_id, 'Cover_Type': y_predict})\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "result = np.c_[test_id.astype(int), output.astype(int)]\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['Id', 'Cover_Type'])\n",
    "df_result.to_csv('all/forest.csv', index=False)\n",
    "\n",
    "print('Compelte')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
